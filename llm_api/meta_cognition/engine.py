# /llm_api/meta_cognition/engine.py
# ã‚¿ã‚¤ãƒˆãƒ«: Meta-Cognition Engine
# å½¹å‰²: ãƒ¡ã‚¿èªçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã®å…¨ä½“ã‚’çµ±åˆã—ã€æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®åˆ†æã€æ”¹å–„ã€é©å¿œã®ã‚µã‚¤ã‚¯ãƒ«ã‚’èª¿æ•´ã™ã‚‹ã€‚

import asyncio
import json
import logging
import re
import time
from collections import deque
from typing import Any, Deque, Dict, List, Optional, cast  # â˜… ä¿®æ­£: castã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

from ..providers.base import LLMProvider
from .optimizer import CognitiveArchitectOptimizer
from .reflection import SelfReflectionEngine
from .types import CognitiveState, ThoughtTrace

logger = logging.getLogger(__name__)


class MetaCognitionEngine:
    """
    ãƒ¡ã‚¿èªçŸ¥ã‚¨ãƒ³ã‚¸ãƒ³ - å…¨ä½“çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã€‚
    è‡ªå·±åçœï¼ˆSelfReflectionEngineï¼‰ã¨èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æœ€é©åŒ–
    ï¼ˆCognitiveArchitectOptimizerï¼‰ã®å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å”èª¿ã•ã›ã€
    ã‚·ã‚¹ãƒ†ãƒ è‡ªèº«ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¶™ç¶šçš„ã«æ”¹å–„ã™ã‚‹ã€‚
    """

    def __init__(self, provider: LLMProvider):
        """
        MetaCognitionEngineã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚

        Args:
            provider: LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚
        """
        self.provider = provider
        self.reflection_engine = SelfReflectionEngine()
        self.architect_optimizer = CognitiveArchitectOptimizer()
        self.current_thought_trace: List[ThoughtTrace] = []
        self.meta_insights_history: Deque[Dict[str, Any]] = deque(maxlen=100)
        self.architecture_config: Dict[str, Any] = {}
        self.cognitive_state = CognitiveState.IDLE
        logger.info("ğŸ¤” Meta-Cognition Engine åˆæœŸåŒ–å®Œäº†")

    async def begin_metacognitive_session(self, problem_context: str) -> Dict[str, Any]:
        """
        æ–°ã—ã„å•é¡Œè§£æ±ºã®ãŸã‚ã®ãƒ¡ã‚¿èªçŸ¥ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™ã€‚

        Args:
            problem_context: è§£æ±ºã™ã¹ãå•é¡Œã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‚

        Returns:
            ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã€å•é¡Œåˆ†æã€åˆæœŸæˆ¦ç•¥ãªã©ã‚’å«ã‚€ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã€‚
        """
        logger.info(f"ãƒ¡ã‚¿èªçŸ¥ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: {problem_context[:50]}...")
        self.current_thought_trace = []
        self.cognitive_state = CognitiveState.ANALYZING

        problem_analysis = await self._analyze_problem_nature(problem_context)
        cognitive_strategy = await self._select_cognitive_strategy(problem_analysis)

        return {
            "session_id": f"meta_{int(time.time())}",
            "problem_analysis": problem_analysis,
            "cognitive_strategy": cognitive_strategy,
            "meta_config": self.architecture_config,
        }

    async def record_thought_step(
        self,
        cognitive_state: CognitiveState,
        context: str,
        reasoning: str,
        confidence: float,
        outputs: Optional[List[str]] = None
    ) -> None:
        """
        æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®ä¸€ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨˜éŒ²ã—ã¾ã™ã€‚

        Args:
            cognitive_state: ç¾åœ¨ã®èªçŸ¥çŠ¶æ…‹ã€‚
            context: ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‚
            reasoning: å®Ÿè¡Œã•ã‚ŒãŸæ¨è«–ã®å†…å®¹ã€‚
            confidence: ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ç¢ºä¿¡åº¦ã€‚
            outputs: ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã®ä¸­é–“å‡ºåŠ›ã€‚
        """
        thought_trace = ThoughtTrace(
            timestamp=time.time(),
            cognitive_state=cognitive_state,
            input_context=context,
            reasoning_step=reasoning,
            confidence_level=confidence,
            resource_usage={"tokens": len(reasoning)},
            intermediate_outputs=outputs or [],
            decision_points=[]
        )
        self.current_thought_trace.append(thought_trace)
        self.reflection_engine.thought_history.append(thought_trace)
        self.cognitive_state = cognitive_state

    async def perform_metacognitive_reflection(self) -> Dict[str, Any]:
        """
        è¨˜éŒ²ã•ã‚ŒãŸæ€è€ƒãƒˆãƒ¬ãƒ¼ã‚¹ã«å¯¾ã—ã¦ãƒ¡ã‚¿èªçŸ¥çš„ãªåçœã‚’å®Ÿè¡Œã—ã€
        ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æœ€é©åŒ–æ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚

        Returns:
            å¾—ã‚‰ã‚ŒãŸæ´å¯Ÿã¨æœ€é©åŒ–æ¡ˆã‚’å«ã‚€è¾æ›¸ã€‚
        """
        logger.info("ãƒ¡ã‚¿èªçŸ¥çš„åçœã‚’å®Ÿè¡Œä¸­...")
        self.cognitive_state = CognitiveState.REFLECTING

        if len(self.current_thought_trace) < 2:
            logger.warning("åçœã™ã‚‹ã«ã¯æ€è€ƒãƒˆãƒ¬ãƒ¼ã‚¹ãŒçŸ­ã™ãã¾ã™ã€‚")
            return {"insights": [], "optimizations": {}}

        # è‡ªå·±åçœã‚¨ãƒ³ã‚¸ãƒ³ã§æ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        insights = await self.reflection_engine.analyze_thought_pattern(self.current_thought_trace)

        # æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ã§æ”¹å–„ç­–ã‚’ç«‹æ¡ˆ
        optimizations = await self.architect_optimizer.optimize_cognitive_architecture(insights)

        # æœ€é©åŒ–æ¡ˆã‚’ç¾åœ¨ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­å®šã«é©ç”¨
        self.architecture_config.update(optimizations)
        for insight in insights:
            self.meta_insights_history.append(vars(insight))

        reflection_result = {
            "insights": [vars(i) for i in insights],
            "optimizations": optimizations,
            "thought_trace_length": len(self.current_thought_trace),
        }

        logger.info(f"ãƒ¡ã‚¿èªçŸ¥çš„åçœå®Œäº†: {len(insights)}å€‹ã®æ´å¯Ÿã€{len(optimizations)}å€‹ã®æœ€é©åŒ–æ¡ˆã‚’ç”Ÿæˆã€‚")
        self.cognitive_state = CognitiveState.ADAPTING
        return reflection_result

    async def _analyze_problem_nature(self, problem: str) -> Dict[str, Any]:
        """LLMã‚’ç”¨ã„ã¦å•é¡Œã®æ€§è³ªã‚’åˆ†æã—ã¾ã™ã€‚"""
        analysis_prompt = f"""
        ä»¥ä¸‹ã®å•é¡Œã®æ€§è³ªã‚’å¤šè§’çš„ã«åˆ†æã—ã€JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
        - cognitive_complexity: èªçŸ¥çš„è¤‡é›‘æ€§ (1-10)
        - thinking_type: å¿…è¦ãªæ€è€ƒã‚¿ã‚¤ãƒ— (ä¾‹: logical, creative, strategic)
        - uncertainty_level: ä¸ç¢ºå®Ÿæ€§ã®ç¨‹åº¦ (1-10)

        å•é¡Œ: "{problem}"
        """
        response = await self.provider.call(analysis_prompt, "")
        try:
            analysis_text = response.get('text', '{}')
            json_match = re.search(r'\{.*\}', analysis_text, re.DOTALL)
            if json_match:
                # â˜… ä¿®æ­£: json.loadsã®çµæœã‚’æœŸå¾…ã•ã‚Œã‚‹å‹ã«ã‚­ãƒ£ã‚¹ãƒˆ
                return cast(Dict[str, Any], json.loads(json_match.group(0)))
            return {}
        except Exception:
            logger.warning("å•é¡Œåˆ†æã®JSONè§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return {}

    async def _select_cognitive_strategy(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """å•é¡Œåˆ†æã«åŸºã¥ã„ã¦èªçŸ¥æˆ¦ç•¥ã‚’é¸æŠã—ã¾ã™ã€‚"""
        complexity = analysis.get("cognitive_complexity", 5)
        uncertainty = analysis.get("uncertainty_level", 5)

        strategy = {"primary_approach": "balanced", "monitoring_frequency": "medium"}

        if complexity >= 8 or uncertainty >= 8:
            strategy["primary_approach"] = "decomposition"
            strategy["monitoring_frequency"] = "high"
        elif analysis.get("thinking_type") == "creative":
            strategy["primary_approach"] = "divergent_convergent"

        return strategy